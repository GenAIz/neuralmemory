{
  "dataset": "logic",
  # input size and target size
  "input_dim": 11,
  "target_dim": 11,
  # eval on train size (first X of train)
  "train_eval_truncate_size": -1,
  "eval_interval": 10,
  # number of actions to retain for training the memory
  "history": 12,
  "settle": 12,
  # use swish over relu
  "use_swish": true,
  # name used to load action NN model
  "action_model": "flatdann",
  # training settings for action model (some of which are used for mem model)
  "epochs": 72,
  "batch_size": 16,
  "eval_batch_size": 256,
  "loss_function": "cross_entropy",
  "action_optimizer": "adam",
  "action_learning_rate": 0.001,
  "action_clipping": 1,
  # name used to load mem NN model
  "mem_model": "flatmnnNA",
  # memory size
  "memory_dim": 48,
  # training settings for the mem model
  "mem_train_iterations": 1,
  "mem_optimizer": "rmsprop",
  "mem_learning_rate": 0.00001,
  "mem_clipping": 1,
  "mem_num_samples": 8,
  "mem_gamma": 0.99,
  "mem_dampen_losses": 3
}
