{
  "dataset": "wmt2014-en",
  "save_point": 32,
  # input size and target size
  "input_dim": 171,
  "target_dim": 171,
  # eval on train size (first X of train)
  "train_eval_truncate_size": 3000,
  "eval_interval": 20,
  "wmt_train_truncate_size": 3000,
  "wmt_validation_truncate_size": 100,
  "wmt_curriculum": [10, 3000],
  "wmt_add_chars_to_curriculum": true,
  # number of actions to retain for training the memory
  "history": 17,
  "settle": 3,
  # name used to load action NN model
  "action_model": "embdann",
  # training settings for action model (some of which are used for mem model)
  "epochs": 2048,
  "batch_size": 16,
  "eval_batch_size": 256,
  "loss_function": "cross_entropy",
  "action_optimizer": "adam",
  "action_learning_rate": 0.00001,
  "action_clipping": 0.01,
  "action_embedding_dim": 96,
  # name used to load mem NN model
  "mem_model": "embWLmnnNA",
  "mem_num_mem_net": 0,
  "mem_embedding_dim": 96,
  "mem_num_intermediate_layers": 0,
  "mem_intermediate_dim": 0,
  # memory size
  "memory_dim": 2048,
  # training settings for the mem model
  "mem_train_iterations": 1,
  "mem_optimizer": "rmsprop",
  "mem_learning_rate": 0.00000001,
  "mem_clipping": 0.001,
  "mem_num_samples": 16,
  "mem_gamma": 0.99,
  "mem_dampen_losses": 8,
  "mem_l1": 2.0,
  "note": "more data but still 2024 mem"
}
